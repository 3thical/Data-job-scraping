{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping seek.com.au for the latest data job information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required modules and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "URL = \"https://www.seek.com.au/data-jobs/in-All-Australia?classification=1209%2C1211%2C6281%2C1223&sortmode=listeddate\"\n",
    "\n",
    "#Page 2 used for testing purposes\n",
    "#URL = \"https://www.seek.com.au/data-jobs/in-All-Australia?classification=1209%2C1211%2C6281%2C1223&page=2&savedsearchid=d3e6e41c-2133-11e9-9978-6b65baccf6af&sortmode=listeddate\"\n",
    "\n",
    "#Make a request for our URL\n",
    "page = requests.get(URL)\n",
    "\n",
    "#Read in the page with BeautifulSoup\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "#Full html code-block can be viewed with print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by pulling out **job titles**. All information for each job post falls within div (*class _3MPUOLE*), so this will be reused a lot. The actual job title is listed as the heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"_3MPUOLE\"}):\n",
    "        for art in div.find_all(name=\"article\"):\n",
    "            for h1 in art.find_all(name=\"h1\"):\n",
    "                jobs.append(h1.text)\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling out **employer names** is a tiny bit more challenging, as some jobs do not list an employer name. These jobs are listed as *Private Advertiser* within a different section (a <span\\>, as opposed to an <a\\>) to where employer names are usually listed. I ended up checking the span for each div first to see if it was listed as private advertiser, in which case I list it as such and move on to the next div. Otherwise, I grab the employer name for each posting from <a\\>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_employer_from_result(soup): \n",
    "    employers = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"_3MPUOLE\"}):\n",
    "        for span in div.find_all(name=\"span\", attrs={\"class\":\"_3FrNV7v _3PZrylH E6m4BZb\"}):\n",
    "            if \"Private Advertiser\" in span.text:\n",
    "                employers.append(\"Private advertiser\")\n",
    "            else:\n",
    "                #for art in div.find_all(name=\"article\"):\n",
    "                for a in span.find_all(name=\"a\", attrs={\"class\":\"_3AMdmRg\"}):\n",
    "                    if a[\"title\"].startswith(\"Jobs at\"):\n",
    "                        employers.append(a[\"title\"][8:])\n",
    "    return(employers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locations** were easy to grab, and it seems mandatory for each posting to have a location listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations_from_result(soup): \n",
    "    locations = []\n",
    "    for span in soup.find_all(name=\"span\", attrs={\"class\":\"Eadjc1o\"}):\n",
    "        if span.text.startswith(\"location\"):\n",
    "            locations.append(span.text[10:])\n",
    "    return (locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the **salary** required adding a placeholder to cover instances where no salary was listed. This is quite common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salaries_from_result(soup):\n",
    "    salaries = []\n",
    "    divs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"xxz8a1h\"}):\n",
    "        try:\n",
    "            salary_block = div.find(name=\"span\", attrs={\"class\":\"lwHBT6d\"})\n",
    "            salaries.append(salary_block.text)\n",
    "        except:\n",
    "            salaries.append(\"Not listed\")\n",
    "            \n",
    "    #Remove any useless info that isn't actually a salary\n",
    "    for i in range(0,len(salaries)):\n",
    "        if \"$\" not in salaries[i]:\n",
    "            salaries[i] = \"Not listed\"\n",
    "            \n",
    "    #Clean up the data a bit for later\n",
    "    salaries = [re.sub(re.escape(\"$\"), \"\", salary) for salary in salaries]\n",
    "    return(salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I wanted to grab the **time since the ad was posted**. The top two ad's on the page are **always** featured ads that don't list a time. It could be a task for the next section to pull this information from the job page directly with Selenium, but it's not super important so labelling them as *featured* for now will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_posted_from_result(soup): \n",
    "    time = ['Featured', 'Featured']\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"_3MPUOLE\"}):\n",
    "        for span in div.find_all(name=\"span\", attrs={\"class\": \"_3FrNV7v _1DHNXoa _1SYpJTv _3PZrylH _2heRYaN E6m4BZb\"}):\n",
    "            time.append(span.text)\n",
    "    time = [i.split(\" \")[0] for i in time]\n",
    "    return(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick comparison of the output of each function used to troubleshoot cases where job postings were being missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employers = 22\n",
      "job titles = 22\n",
      "locations = 22\n",
      "salaries = 22\n",
      "time = 22\n"
     ]
    }
   ],
   "source": [
    "x = len(extract_employer_from_result(soup))\n",
    "y = len(extract_job_title_from_result(soup))\n",
    "z = len(extract_locations_from_result(soup))\n",
    "zx = len(extract_salaries_from_result(soup))\n",
    "zxc = len(extract_time_posted_from_result(soup))\n",
    "\n",
    "print (\"employers = {}\\njob titles = {}\\nlocations = {}\\nsalaries = {}\\ntime = {}\".format(x,y,z,zx,zxc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pool everything I've got so far into a dataframe. At this point I could loop through each search page to make a much more comprehensive dataframe, but for now I'll focus on just the first page of strictly the most recent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.DataFrame({\"time_posted\": extract_time_posted_from_result(soup),\n",
    "                       \"job_title\": extract_job_title_from_result(soup),\n",
    "                       \"employer\": extract_employer_from_result(soup),\n",
    "                       \"location\": extract_locations_from_result(soup),\n",
    "                       \"salary\": extract_salaries_from_result(soup)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_posted</th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Featured</td>\n",
       "      <td>Data Engineer - Energy Efficiency</td>\n",
       "      <td>Eutility Pty Ltd</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Not listed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Featured</td>\n",
       "      <td>Civil Engineer</td>\n",
       "      <td>East Arm Civil Pty Ltd</td>\n",
       "      <td>Darwin</td>\n",
       "      <td>100,000 - 149,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45m</td>\n",
       "      <td>Senior Systems Engineer</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>Perth</td>\n",
       "      <td>90k - 115k p.a. + super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1h</td>\n",
       "      <td>Application Security Specialist</td>\n",
       "      <td>Balance Recruitment</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Not listed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1h</td>\n",
       "      <td>Network Operator</td>\n",
       "      <td>Foxtel</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Not listed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_posted                          job_title                employer  \\\n",
       "0    Featured  Data Engineer - Energy Efficiency        Eutility Pty Ltd   \n",
       "1    Featured                     Civil Engineer  East Arm Civil Pty Ltd   \n",
       "2         45m            Senior Systems Engineer             Robert Half   \n",
       "3          1h    Application Security Specialist     Balance Recruitment   \n",
       "4          1h                   Network Operator                  Foxtel   \n",
       "\n",
       "  location                   salary  \n",
       "0   Sydney               Not listed  \n",
       "1   Darwin        100,000 - 149,999  \n",
       "2    Perth  90k - 115k p.a. + super  \n",
       "3   Sydney               Not listed  \n",
       "4   Sydney               Not listed  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Grab job descriptions with Selenium"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
