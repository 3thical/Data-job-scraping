{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping seek.com.au for the latest data job information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required modules and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "URL = \"https://www.seek.com.au/data-jobs/in-All-Australia?classification=1209%2C1211%2C6281%2C1223&sortmode=listeddate\"\n",
    "\n",
    "#Page 2 used for testing purposes\n",
    "#URL = \"https://www.seek.com.au/data-jobs/in-All-Australia?classification=1209%2C1211%2C6281%2C1223&page=2&savedsearchid=d3e6e41c-2133-11e9-9978-6b65baccf6af&sortmode=listeddate\"\n",
    "\n",
    "#Make a request for our URL\n",
    "page = requests.get(URL)\n",
    "\n",
    "#Read in the page with BeautifulSoup\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "#Full html code-block can be viewed with print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by pulling out **job titles**. All information for each job post falls within div (*class _3MPUOLE*), so this will be reused a lot. The actual job title is listed as the heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"_3MPUOLE\"}):\n",
    "        for art in div.find_all(name=\"article\"):\n",
    "            for h1 in art.find_all(name=\"h1\"):\n",
    "                jobs.append(h1.text)\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling out **employer names** is a tiny bit more challenging, as some jobs do not list an employer name. These jobs are listed as *Private Advertiser* within a different section (a <span\\>, as opposed to an <a\\>) to where employer names are usually listed. I ended up checking the span for each div first to see if it was listed as private advertiser, in which case I list it as such and move on to the next div. Otherwise, I grab the employer name for each posting from <a\\>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_employer_from_result(soup): \n",
    "    employers = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"_3MPUOLE\"}):\n",
    "        for span in div.find_all(name=\"span\", attrs={\"class\":\"_3FrNV7v _3PZrylH E6m4BZb\"}):\n",
    "            if \"Private Advertiser\" in span.text:\n",
    "                employers.append(\"Private advertiser\")\n",
    "            else:\n",
    "                #for art in div.find_all(name=\"article\"):\n",
    "                for a in span.find_all(name=\"a\", attrs={\"class\":\"_3AMdmRg\"}):\n",
    "                    if a[\"title\"].startswith(\"Jobs at\"):\n",
    "                        employers.append(a[\"title\"][8:])\n",
    "    return(employers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locations** were easy to grab, and it seems mandatory for each posting to have a location listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations_from_result(soup): \n",
    "    locations = []\n",
    "    for span in soup.find_all(name=\"span\", attrs={\"class\":\"Eadjc1o\"}):\n",
    "        if span.text.startswith(\"location\"):\n",
    "            locations.append(span.text[10:])\n",
    "    return (locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the **salary** required adding a placeholder to cover instances where no salary was listed. This is quite common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salaries_from_result(soup):\n",
    "    salaries = []\n",
    "    divs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"xxz8a1h\"}):\n",
    "        try:\n",
    "            salary_block = div.find(name=\"span\", attrs={\"class\":\"lwHBT6d\"})\n",
    "            salaries.append(salary_block.text)\n",
    "        except:\n",
    "            salaries.append(\"NaN\")\n",
    "            \n",
    "    #Remove any useless info that isn't actually useful salary information\n",
    "    for i in range(0,len(salaries)):\n",
    "        if \"$\" not in salaries[i]:\n",
    "            salaries[i] = \"NaN\"\n",
    "            \n",
    "    #Clean up the data a bit for later\n",
    "    salaries = [re.sub(re.escape(\"$\"), \"\", salary) for salary in salaries]\n",
    "    return(salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to grab the **time since the ad was posted**. The top two ad's on the page are **always** featured ads that don't list a time. It could be a task for the next section to pull this information from the job page directly with Selenium, but it's not super important so labelling them as *featured* for now will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_posted_from_result(soup): \n",
    "    time = ['Featured', 'Featured']\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"_3MPUOLE\"}):\n",
    "        for span in div.find_all(name=\"span\", attrs={\"class\": \"_3FrNV7v _1DHNXoa _1SYpJTv _3PZrylH _2heRYaN E6m4BZb\"}):\n",
    "            time.append(span.text)\n",
    "    time = [i.split(\" \")[0] for i in time]\n",
    "    return(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I'll grab the url's (href) for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.seek.com.au/job/38144608?type=promoted&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38177007?type=promoted&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296531?type=standout&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296526?type=standout&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296522?type=standout&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296521?type=standout&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296517?type=standout&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296508?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296507?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296504?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296494?type=standout&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296485?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296475?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296465?type=standout&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296446?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296430?type=standout&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296409?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296368?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296340?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296341?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296311?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954',\n",
       " 'http://www.seek.com.au/job/38296304?type=standard&searchrequesttoken=d8cb499b-a256-44bd-b750-ee34aa574954']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grab_urls_from_result(soup): \n",
    "    base_url = \"http://www.seek.com.au\"\n",
    "    urls = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"_3MPUOLE\"}):\n",
    "        for art in div.find_all(name=\"article\"):\n",
    "            for h1 in art.find_all(name='h1'):\n",
    "                for a in h1.find_all(name=\"a\"):\n",
    "                    urls.append(base_url + a['href'])\n",
    "    return(urls)\n",
    "grab_urls_from_result(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick comparison of the output of each function used to troubleshoot cases where job postings were being missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employers = 22\n",
      "job titles = 22\n",
      "locations = 22\n",
      "salaries = 22\n",
      "time = 22\n",
      "urls = 22\n"
     ]
    }
   ],
   "source": [
    "x = len(extract_employer_from_result(soup))\n",
    "y = len(extract_job_title_from_result(soup))\n",
    "z = len(extract_locations_from_result(soup))\n",
    "zx = len(extract_salaries_from_result(soup))\n",
    "zxc = len(extract_time_posted_from_result(soup))\n",
    "zxcv = len(grab_urls_from_result(soup))\n",
    "\n",
    "print (\"employers = {}\\njob titles = {}\\nlocations = {}\\nsalaries = {}\\ntime = {}\\nurls = {}\".format(x,y,z,zx,zxc,zxcv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pool everything I've got so far into a dataframe. At this point I could loop through each search page to make a much more comprehensive dataframe, but for now I'll focus on just the first page of strictly the most recent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.DataFrame({\"time_posted\": extract_time_posted_from_result(soup),\n",
    "                       \"job_title\": extract_job_title_from_result(soup),\n",
    "                       \"employer\": extract_employer_from_result(soup),\n",
    "                       \"location\": extract_locations_from_result(soup),\n",
    "                       \"salary\": extract_salaries_from_result(soup),\n",
    "                       \"url\": grab_urls_from_result(soup)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_posted</th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Featured</td>\n",
       "      <td>Data Engineer - Energy Efficiency</td>\n",
       "      <td>Eutility Pty Ltd</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.seek.com.au/job/38144608?type=promo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Featured</td>\n",
       "      <td>Electrical engineer; Industrial IoT</td>\n",
       "      <td>Collective Intelligence Group</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.seek.com.au/job/38177007?type=promo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5m</td>\n",
       "      <td>PMO Analyst</td>\n",
       "      <td>Peoplebank Australia</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.seek.com.au/job/38296531?type=stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5m</td>\n",
       "      <td>Account Executive</td>\n",
       "      <td>Halcyon Knights</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>240,000 - 280,000 per year OTE 60/40</td>\n",
       "      <td>http://www.seek.com.au/job/38296526?type=stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5m</td>\n",
       "      <td>Project Manager - Brisbane</td>\n",
       "      <td>Paxus</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.seek.com.au/job/38296522?type=stand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_posted                            job_title  \\\n",
       "0    Featured    Data Engineer - Energy Efficiency   \n",
       "1    Featured  Electrical engineer; Industrial IoT   \n",
       "2          5m                          PMO Analyst   \n",
       "3          5m                    Account Executive   \n",
       "4          5m           Project Manager - Brisbane   \n",
       "\n",
       "                        employer   location  \\\n",
       "0               Eutility Pty Ltd     Sydney   \n",
       "1  Collective Intelligence Group     Sydney   \n",
       "2           Peoplebank Australia     Sydney   \n",
       "3                Halcyon Knights     Sydney   \n",
       "4                          Paxus  Melbourne   \n",
       "\n",
       "                                 salary  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3  240,000 - 280,000 per year OTE 60/40   \n",
       "4                                   NaN   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.seek.com.au/job/38144608?type=promo...  \n",
       "1  http://www.seek.com.au/job/38177007?type=promo...  \n",
       "2  http://www.seek.com.au/job/38296531?type=stand...  \n",
       "3  http://www.seek.com.au/job/38296526?type=stand...  \n",
       "4  http://www.seek.com.au/job/38296522?type=stand...  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Grab job descriptions with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems each paragraph <p\\> is contained within a div that can belong to one of two classes. Here i've simply iterated over each, checked if they've grabbed any info, and if so append them to my list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/chris/chromedriver.exe')\n",
    "\n",
    "descriptions = []\n",
    "for url in grab_urls_from_result(soup):\n",
    "    driver.get(url)\n",
    "    info = driver.find_elements_by_xpath('//div[@class=\"templatetext\"]')\n",
    "    \n",
    "    if len(info) != 0:\n",
    "        descriptions.append(info[0].text)\n",
    "    else:\n",
    "        info = driver.find_elements_by_xpath('//div[@class=\"_2e4Pi2B\"]')\n",
    "        if len(info) != 0:\n",
    "            descriptions.append(info[0].text)\n",
    "        else:\n",
    "            descriptions += \"NaN\"\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the descriptions to a new column in my dataframe and write it out to an excel file, although this is commented out as I've made some ammendements below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df['description'] = descriptions\n",
    "#job_df.to_excel(\"jobs.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full job descriptions end up being a bit long-winded, but really I just want to see if a few key words are present in the description, then maybe I'll have a closer look at the job description directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_word_search(descriptions):\n",
    "    '''takes a list of jobs descriptions and \n",
    "       checks for the presence of any keywords'''\n",
    "\n",
    "    key_words = ('junior', 'graduate', 'python', ' R ', ' R.', 'scripting')\n",
    "    temp = []\n",
    "    words_found = []\n",
    "    \n",
    "    for i in descriptions:\n",
    "        for word in key_words:\n",
    "            if word in i.lower():\n",
    "                temp.append(word)\n",
    "        if len(temp) == 0:\n",
    "            words_found.append('NaN')\n",
    "        else:\n",
    "            words_found.append(', '.join(temp))\n",
    "            temp = []\n",
    "    return(words_found) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly it would be good to know if the job requires a certain amount of experience at a glance, so I'll do a quick search of each description and if anything matches I'll save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_search(descriptions):\n",
    "    '''takes a list of job descriptions and\n",
    "    searches for the required amount of experience'''\n",
    "    \n",
    "    experience = []\n",
    "    for description in descriptions:\n",
    "        try:\n",
    "            experience.append(re.search(r'\\d+[+]* years*', description).group()) #expression needs work will look into this\n",
    "        except:\n",
    "            experience.append('NaN')\n",
    "    return(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 years',\n",
       " '3+ years',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " '3 years',\n",
       " '60 years',\n",
       " '4+ years',\n",
       " '2+ years',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_search(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_posted</th>\n",
       "      <th>job_title</th>\n",
       "      <th>employer</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>experience</th>\n",
       "      <th>key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Featured</td>\n",
       "      <td>Data Engineer - Energy Efficiency</td>\n",
       "      <td>Eutility Pty Ltd</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.seek.com.au/job/38144608?type=promo...</td>\n",
       "      <td>Eutility have a new role within an expanding e...</td>\n",
       "      <td>3 years experience</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Featured</td>\n",
       "      <td>Electrical engineer; Industrial IoT</td>\n",
       "      <td>Collective Intelligence Group</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.seek.com.au/job/38177007?type=promo...</td>\n",
       "      <td>The Collective Intelligence Group is a global ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>python, scripting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5m</td>\n",
       "      <td>PMO Analyst</td>\n",
       "      <td>Peoplebank Australia</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.seek.com.au/job/38296531?type=stand...</td>\n",
       "      <td>My client, a large global bank is looking for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_posted                            job_title  \\\n",
       "0    Featured    Data Engineer - Energy Efficiency   \n",
       "1    Featured  Electrical engineer; Industrial IoT   \n",
       "2          5m                          PMO Analyst   \n",
       "\n",
       "                        employer location salary  \\\n",
       "0               Eutility Pty Ltd   Sydney    NaN   \n",
       "1  Collective Intelligence Group   Sydney    NaN   \n",
       "2           Peoplebank Australia   Sydney    NaN   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.seek.com.au/job/38144608?type=promo...   \n",
       "1  http://www.seek.com.au/job/38177007?type=promo...   \n",
       "2  http://www.seek.com.au/job/38296531?type=stand...   \n",
       "\n",
       "                                         description          experience  \\\n",
       "0  Eutility have a new role within an expanding e...  3 years experience   \n",
       "1  The Collective Intelligence Group is a global ...                 NaN   \n",
       "2  My client, a large global bank is looking for ...                 NaN   \n",
       "\n",
       "           key_words  \n",
       "0             python  \n",
       "1  python, scripting  \n",
       "2                NaN  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df['experience'] = experience_search(descriptions)\n",
    "job_df['key_words'] = key_word_search(descriptions)\n",
    "job_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.to_excel(\"jobs.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
